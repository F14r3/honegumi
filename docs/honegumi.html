<!DOCTYPE html>
<html>

<head>
    <title>Interactive Grid Example</title>
    <style>
        input[type="radio"] {
            opacity: 0;
            position: absolute;
            width: 0;
            height: 0;
        }

        form {
            display: inline-flex;
            flex-direction: column;
        }

        .row {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            background-color: #f2f2f2;
            border: 0px solid #ccc;
        }

        .row label {
            display: inline-block;
            border: 1px solid #ccc;
            padding: 5px;
            cursor: pointer;
            background-color: #f2f2f2;
            text-align: center;
        }

        input[type="radio"]:checked+label {
            background-color: #b1b1b1;
        }
    </style>
    <link rel="stylesheet" href="_static/prism/prism.css">
</head>

<body onload="updateText()">
    <script>
        var optionRows = [{"hidden": false, "name": "objective", "options": ["single", "multi"]}, {"hidden": false, "name": "model", "options": ["GPEI", "FULLYBAYESIAN"]}, {"hidden": false, "name": "use_existing_data", "options": ["False", "True"]}, {"hidden": false, "name": "use_constraint", "options": ["False", "True"]}, {"hidden": false, "name": "use_categorical", "options": ["False", "True"]}, {"hidden": false, "name": "use_custom_threshold", "options": ["False", "True"]}];
        // E.g.,
        // var optionRows = [
        //     { "name": "row1", "options": ["A", "B"] },
        //     { "name": "row2", "options": ["C", "D", "E"] },
        //     { "name": "row3", "options": ["F", "G"] }
        // ];

        var scriptLookup = {"multi,FULLYBAYESIAN,False,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,False,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,False,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,True,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,False,True,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,False,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,False,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,True,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,FULLYBAYESIAN,True,True,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIANMOO,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,False,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,False,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,True,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,False,True,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,False,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,False,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,True,False,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n        obj2_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "multi,GPEI,True,True,True,True": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\nobj2_name = \"branin_swapped\"\n\n\ndef branin_moo(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    # second objective has x1 and x2 swapped\n    y2 = float(\n        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)\n        + 10\n    )\n\n    # add a categorical penalty\n    penalty_lookup = {\"A\": 0.0, \"B\": 2.0, \"C\": 1.0}\n    y2 += penalty_lookup[c1]\n\n    return {obj1_name: y, obj2_name: y2}\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin_moo(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),\n        obj2_name: ObjectiveProperties(minimize=True, threshold=25.0),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin_moo(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\npareto_results = ax_client.get_pareto_optimal_parameters()\n", "single,FULLYBAYESIAN,False,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,False,False,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,False,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,False,False,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,False,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,False,True,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,False,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,False,True,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,True,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,True,False,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,True,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,True,False,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,True,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,True,True,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,FULLYBAYESIAN,True,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nfrom ax.modelbridge.factory import Models\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\ngs = GenerationStrategy(\n    steps=[\n        GenerationStep(\n            model=Models.SOBOL,\n            num_trials=5,\n            min_trials_observed=3,\n            max_parallelism=5,\n            model_kwargs={\"seed\": 999},\n            model_gen_kwargs={},\n        ),\n        GenerationStep(\n            model=Models.FULLYBAYESIAN,\n            num_trials=-1,\n            max_parallelism=3,\n            model_kwargs={\"num_samples\": 256, \"warmup_steps\": 512},\n        ),\n    ]\n)\n\nax_client = AxClient(generation_strategy=gs)\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,FULLYBAYESIAN,True,True,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,False,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,False,False,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,False,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,False,False,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,False,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,False,True,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,False,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,False,True,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,True,False,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,True,False,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,True,False,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,True,False,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,True,True,False,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\n            \"x1\": -3.0,\n            \"x2\": 2.0,\n        },\n        {\n            \"x1\": 0.0,\n            \"x2\": 7.0,\n        },\n        {\n            \"x1\": 3.0,\n            \"x2\": 5.0,\n        },\n        {\n            \"x1\": 5.0,\n            \"x2\": 0.0,\n        },\n        {\n            \"x1\": 10.0,\n            \"x2\": 10.0,\n        },\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(\n        parameters[\"x1\"],\n        parameters[\"x2\"],\n    )\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,True,True,False,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent.", "single,GPEI,True,True,True,False": "import numpy as np\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\n\n\nimport pandas as pd\n\nobj1_name = \"branin\"\n\n\ndef branin(x1, x2, c1):\n    y = float(\n        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n        + 10\n    )\n\n    # add a categorical penalty (only to y)\n    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n    y += penalty_lookup[c1]\n\n    return y\n\n\n# Define the training data\nX_train = pd.DataFrame(\n    [\n        {\"x1\": -3.0, \"x2\": 2.0, \"c1\": \"A\"},\n        {\"x1\": 0.0, \"x2\": 7.0, \"c1\": \"B\"},\n        {\"x1\": 3.0, \"x2\": 5.0, \"c1\": \"C\"},\n        {\"x1\": 5.0, \"x2\": 0.0, \"c1\": \"A\"},\n        {\"x1\": 10.0, \"x2\": 10.0, \"c1\": \"B\"},\n    ]\n)\n\n# Calculate y_train using the objective function\ny_train = [branin(row[\"x1\"], row[\"x2\"], row[\"c1\"]) for _, row in X_train.iterrows()]\n\n\n# Define the number of training examples\nn_train = len(X_train)\n\n\nax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n        {\n            \"name\": \"c1\",\n            \"type\": \"choice\",\n            \"is_ordered\": False,\n            \"values\": [\"A\", \"B\", \"C\"],\n        },\n    ],\n    objectives={\n        obj1_name: ObjectiveProperties(minimize=True),\n    },\n    parameter_constraints=[\n        \"x1 + x2 \u003c= 20.0\",  # sum constraint example\n        \"x1 \u003c= x2\",  # order constraint example\n        \"1.0*x1 + 0.5*x2 \u003c= 10.0\",  # linear constraint example (note there is no space around operator *)\n    ],\n)\n\n# Add existing data to the AxClient\nfor i in range(n_train):\n    ax_client.attach_trial(X_train.iloc[i].to_dict())\n    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n\nfor _ in range(10):\n    parameters, trial_index = ax_client.get_next_trial()\n    results = branin(parameters[\"x1\"], parameters[\"x2\"], parameters[\"c1\"])\n    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n\n\nbest_parameters, metrics = ax_client.get_best_parameters()\n", "single,GPEI,True,True,True,True": "INVALID: The parameters you have selected are incompatible, either from not being implemented or being logically inconsistent."};
        // E.g.,
        // var lookup = {
        //     "A,C,F": "ACF",
        //     "A,C,G": "INVALID",
        //     "A,D,F": "ADF",
        //     "A,D,G": "ADG",
        //     "A,E,F": "AEF",
        //     "A,E,G": "AEG",
        //     "B,C,F": "BCF",
        //     "B,C,G": "BCG",
        //     "B,D,F": "INVALID",
        //     "B,D,G": "BDG",
        //     "B,E,F": "INVALID",
        //     "B,E,G": "BEG"
        // };

        var preambleLookup = {"multi,FULLYBAYESIAN,False,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,False,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,False,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,True,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,False,True,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,False,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,False,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,True,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,FULLYBAYESIAN,True,True,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,False,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,False,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,True,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,False,True,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,False,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,False,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,True,False,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "multi,GPEI,True,True,True,True": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-True.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-multi__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-True.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,False,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,False,False,False,True": "\n", "single,FULLYBAYESIAN,False,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,False,False,True,True": "\n", "single,FULLYBAYESIAN,False,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,False,True,False,True": "\n", "single,FULLYBAYESIAN,False,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,False,True,True,True": "\n", "single,FULLYBAYESIAN,True,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,True,False,False,True": "\n", "single,FULLYBAYESIAN,True,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,True,False,True,True": "\n", "single,FULLYBAYESIAN,True,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,True,True,False,True": "\n", "single,FULLYBAYESIAN,True,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-FULLYBAYESIAN__use_custom_gen-True__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,FULLYBAYESIAN,True,True,True,True": "\n", "single,GPEI,False,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,False,False,False,True": "\n", "single,GPEI,False,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,False,False,True,True": "\n", "single,GPEI,False,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,False,True,False,True": "\n", "single,GPEI,False,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-False__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,False,True,True,True": "\n", "single,GPEI,True,False,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,True,False,False,True": "\n", "single,GPEI,True,False,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-False__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,True,False,True,True": "\n", "single,GPEI,True,True,False,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-False__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,True,True,False,True": "\n", "single,GPEI,True,True,True,False": "\u003ca href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs\\generated_notebooks\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.ipynb\"\u003e\u003cimg alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/sgbaird/honegumi/tree/main/docs\\generated_scripts\\ax\\objective-single__model-GPEI__use_custom_gen-False__use_existing_data-True__use_constraint-True__use_categorical-True__use_custom_threshold-False.py\"\u003e\u003cimg alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open%20in%20GitHub-blue?logo=github\u0026labelColor=grey\"\u003e\u003c/a\u003e", "single,GPEI,True,True,True,True": "\n"};

        var invalidConfigs = [["single", "GPEI", "False", "False", "False", "True"], ["single", "GPEI", "False", "False", "True", "True"], ["single", "GPEI", "False", "True", "False", "True"], ["single", "GPEI", "False", "True", "True", "True"], ["single", "GPEI", "True", "False", "False", "True"], ["single", "GPEI", "True", "False", "True", "True"], ["single", "GPEI", "True", "True", "False", "True"], ["single", "GPEI", "True", "True", "True", "True"], ["single", "FULLYBAYESIAN", "False", "False", "False", "True"], ["single", "FULLYBAYESIAN", "False", "False", "True", "True"], ["single", "FULLYBAYESIAN", "False", "True", "False", "True"], ["single", "FULLYBAYESIAN", "False", "True", "True", "True"], ["single", "FULLYBAYESIAN", "True", "False", "False", "True"], ["single", "FULLYBAYESIAN", "True", "False", "True", "True"], ["single", "FULLYBAYESIAN", "True", "True", "False", "True"], ["single", "FULLYBAYESIAN", "True", "True", "True", "True"]];
        // E.g.,
        // var invalidConfigs = [
        //     ["B", "D", "F"],
        //     ["B", "E", "F"],
        //     ["A", "C", "G"]
        // ];
    </script>

    <form>
        <div class="title-block">
            <div class="row align-items-center">
                <img src="_static/logo.png" alt="Logo" style="height: 2em; margin-right: 1em; vertical-align: middle;">
                <h2 style="margin-bottom: 0;">Honegumi</h2>
            </div>
        </div>

        <div class="row">
            <label style="width: 20ch; pointer-events: none; cursor: default; text-align: left; border: none; border-left: 3px solid #868686;">
                objective:
            </label>

            <input type="radio" id="objective-single" name="objective" value="single" checked onclick="updateText()">
            <label for="objective-single" style="flex-basis: 50.0%">single</label>

            <input type="radio" id="objective-multi" name="objective" value="multi" onclick="updateText()">
            <label for="objective-multi" style="flex-basis: 50.0%">multi</label>

        </div>

        <div class="row">
            <label style="width: 20ch; pointer-events: none; cursor: default; text-align: left; border: none; border-left: 3px solid #868686;">
                model:
            </label>

            <input type="radio" id="model-GPEI" name="model" value="GPEI" checked onclick="updateText()">
            <label for="model-GPEI" style="flex-basis: 50.0%">GPEI</label>

            <input type="radio" id="model-FULLYBAYESIAN" name="model" value="FULLYBAYESIAN" onclick="updateText()">
            <label for="model-FULLYBAYESIAN" style="flex-basis: 50.0%">FULLYBAYESIAN</label>

        </div>

        <div class="row">
            <label style="width: 20ch; pointer-events: none; cursor: default; text-align: left; border: none; border-left: 3px solid #868686;">
                use_existing_data:
            </label>

            <input type="radio" id="use_existing_data-False" name="use_existing_data" value="False" checked onclick="updateText()">
            <label for="use_existing_data-False" style="flex-basis: 50.0%">False</label>

            <input type="radio" id="use_existing_data-True" name="use_existing_data" value="True" onclick="updateText()">
            <label for="use_existing_data-True" style="flex-basis: 50.0%">True</label>

        </div>

        <div class="row">
            <label style="width: 20ch; pointer-events: none; cursor: default; text-align: left; border: none; border-left: 3px solid #868686;">
                use_constraint:
            </label>

            <input type="radio" id="use_constraint-False" name="use_constraint" value="False" checked onclick="updateText()">
            <label for="use_constraint-False" style="flex-basis: 50.0%">False</label>

            <input type="radio" id="use_constraint-True" name="use_constraint" value="True" onclick="updateText()">
            <label for="use_constraint-True" style="flex-basis: 50.0%">True</label>

        </div>

        <div class="row">
            <label style="width: 20ch; pointer-events: none; cursor: default; text-align: left; border: none; border-left: 3px solid #868686;">
                use_categorical:
            </label>

            <input type="radio" id="use_categorical-False" name="use_categorical" value="False" checked onclick="updateText()">
            <label for="use_categorical-False" style="flex-basis: 50.0%">False</label>

            <input type="radio" id="use_categorical-True" name="use_categorical" value="True" onclick="updateText()">
            <label for="use_categorical-True" style="flex-basis: 50.0%">True</label>

        </div>

        <div class="row">
            <label style="width: 20ch; pointer-events: none; cursor: default; text-align: left; border: none; border-left: 3px solid #868686;">
                use_custom_threshold:
            </label>

            <input type="radio" id="use_custom_threshold-False" name="use_custom_threshold" value="False" checked onclick="updateText()">
            <label for="use_custom_threshold-False" style="flex-basis: 50.0%">False</label>

            <input type="radio" id="use_custom_threshold-True" name="use_custom_threshold" value="True" onclick="updateText()">
            <label for="use_custom_threshold-True" style="flex-basis: 50.0%">True</label>

        </div>

        <div class="row align-items-end">
            <p id="preamble"></p>
        </div>
        <div class="row">
        <pre class="language-python" style="width: 88ch; overflow: auto; font-size: 12px;">
            <code id="text" style="border: none;"></code>
        </pre>
        </div>

    </form>
    <script>
        function updateText() {
            var rows = document.querySelectorAll('input[type="radio"]:checked');
            // Remove strikethrough formatting from all labels except for the selected radio button's label
            // While not strictly necessary, it prevents a possible "disappear/appear" effect
            var labels = document.querySelectorAll('label');
            labels.forEach(function (label) {
                if (label.htmlFor !== rows.id) {
                    label.innerHTML = label.textContent;
                }
            });
            var key = Array.from(rows, function (row) { return row.value; }).join(',');
            var rendered = scriptLookup[key];
            var preamble = preambleLookup[key];

            // Update the GitHub link
            document.getElementById("preamble").innerHTML = preamble
            document.getElementById("text").innerHTML = "\n" + rendered;
            var currentConfig = Array.from(rows, function (row) { return row.value; });

            // Generate all possible configurations that deviate by zero or one option from the current configuration
            var possibleDeviatingConfigs = [];
            for (var i = 0; i < optionRows.length; i++) {
                var options = optionRows[i]['options'];
                for (var j = 0; j < options.length; j++) {
                    var option = options[j];
                    var deviation = currentConfig.slice();
                    deviation[i] = option;
                    possibleDeviatingConfigs.push(deviation);
                }
            }
            // Remove duplicates
            possibleDeviatingConfigs = possibleDeviatingConfigs.filter(function (config, index) {
                return possibleDeviatingConfigs.indexOf(config) === index;
            });

            // Find the invalid configurations that match the deviating configurations
            var deviatingConfigs = [];
            for (var i = 0; i < invalidConfigs.length; i++) {
                var config = invalidConfigs[i];
                if (possibleDeviatingConfigs.some(function (deviation) {
                    return deviation.every(function (value, index) {
                        return value === config[index];
                    });
                })) {
                    deviatingConfigs.push(config);
                }
            }
            // Track the one option that was the deviation for each deviating config
            var deviatingOptions = deviatingConfigs.map(function (config) {
                var deviatingIndex = config.findIndex(function (value, index) {
                    return value !== currentConfig[index];
                });
                return optionRows[deviatingIndex]['name'] + '-' + config[deviatingIndex];
            });

            // Check if the current configuration is invalid
            var isInvalid = invalidConfigs.some(function (config) {
                return config.every(function (value, index) {
                    return value === currentConfig[index];
                });
            });

            // If the current configuration is invalid, add all selected options to the list of deviatingOptions
            if (isInvalid) {
                var currentConfigWithName = currentConfig.map(function (value, index) {
                    return optionRows[index]['name'] + '-' + value;
                });
                deviatingOptions = deviatingOptions.concat(currentConfigWithName);
            }

            // Logging (OK to comment out)
            console.group('Current Config');
            console.table(currentConfig);
            console.group('Deviations');
            console.group('Possible Deviating Configs');
            console.table(possibleDeviatingConfigs);
            console.groupEnd();
            console.group('Deviating Configs');
            console.table(deviatingConfigs);
            console.groupEnd();
            console.group('Deviating Options');
            console.table(deviatingOptions);
            console.groupEnd();
            console.groupEnd();

            // Add strikethrough for each deviating option
            deviatingOptions.forEach(function (option) {
                var label = document.querySelector('label[for="' + option + '"]');
                if (label) {
                    label.innerHTML = '<s>' + label.innerHTML + '</s>';
                }
            });
            Prism.highlightAll();
        }
    </script>
    <script src="_static/prism/prism.js"></script>
</body>

</html>

<!-- // Generate all possible configurations that deviate by zero or one option from the current configuration
// start with current config
var possibleDeviatingConfigs = [currentConfig.slice()]; -->
